# Training configuration for DDPM_UNet
# Device configuration
device: auto  # Options: auto, cuda, mps, cpu

# Distributed training configuration
distributed:
  enabled: false
  find_unused_parameters: false

# Model configuration
model:
  type: DDPM_UNet
  params:
    img_channels: 3
    base_channels: 256
    channel_mults: [1, 1, 2, 2, 4, 4]
    num_res_blocks: 2
    time_emb_dim: 256
    num_classes: 45
    dropout: 0.1
    attn_resolutions: [3, 4, 5] # 从0开始表示，对应channel_mults中
    num_groups: 32
    init_pad: 0
    act: silu
    num_heads: 1

# Engine configuration
engine:
  type: DDPM_UNet
  params:
    num_timesteps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: linear

# Data configuration
data:
  train:
    path: data/NWPU-RESISC45/train
    batch_size: 2  # total_batch = batch * accumulation_steps
    shuffle: true
    num_workers: 4
    pin_memory: true
    has_labels: true
  
  val:
    path: data/NWPU-RESISC45/val
    batch_size: 2
    shuffle: false
    num_workers: 4
    pin_memory: true
    has_labels: true

# Process configuration
process:
  train:
    num_epochs: 100
    save_dir: ./results/DDPM_UNet/NWPU-RESISC45_with_ema_batch_accu
    save_freq: 10
    log_freq: 100
    gradient_clip: null
    resume_from: null
    tensorboard_dir: ./results/DDPM_UNet/NWPU-RESISC45_with_ema_batch_accu/tensorboard  # null to disable TensorBoard
    accumulation_steps: 64  # total_batch = batch * accumulation_steps
    mixed_precision: bf16  # null, fp16, bf16
    ema_decay: 0.9999  # null to disable, typically 0.999 or 0.9999
    
    # Optimizer parameters
    lr: 0.0001
    weight_decay: 0.0
    betas: [0.9, 0.999]
    
    # Scheduler parameters
    scheduler_type: cosine
    warmup_epochs: 3
