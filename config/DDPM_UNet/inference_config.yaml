# Inference configuration for DDPM_UNet
# Device configuration
device: auto  # Options: auto, cuda, mps, cpu

# Model configuration
model:
  type: DDPM_UNet
  params:
    img_channels: 3
    base_channels: 64
    channel_mults: [1, 2, 4, 8]
    num_res_blocks: 2
    time_emb_dim: 256
    num_classes: null  # Set to number of classes for conditional generation, null for unconditional
    dropout: 0.1
    attn_resolutions: [1]
    num_groups: 32
    init_pad: 0
    act: relu

# Engine configuration
engine:
  type: DDPM_UNet
  params:
    num_timesteps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: linear

# Process configuration
process:
  inference:
    checkpoint_path: ./checkpoints/checkpoint_epoch_100.pt  # Path to checkpoint to load
    save_dir: ./inference_results
    
    # Generation parameters
    num_samples: 4  # Number of samples to generate
    batch_size: 1  # Batch size for generation
    img_shape: [3, 32, 32]  # Image shape [C, H, W]
    
    # Conditional generation (if using class labels)
    labels: null  # Set to list of class indices for conditional generation, or null
    
    # Sampling parameters
    guidance_scale: 1.0  # Classifier-free guidance scale (if > 1.0)
    ddim: false  # Use DDIM sampling (faster) instead of DDPM
    ddim_steps: 50  # Number of steps for DDIM sampling
